# Telegram EDA Starter (промежуточная версия)

Проект для анализа текстов Telegram-каналов.  
Цель — собрать данные из открытых источников и провести базовую обработку и разведочный анализ.

---

## 1. Сбор данных

В качестве тестового источника выбран канал [@rbc_news](https://t.me/rbc_news).  
Используется библиотека **Telethon** для подключения к Telegram API.  

Основные шаги:
- авторизация по номеру телефона и коду (с поддержкой 2FA);
- парсинг постов (пример — 2000 сообщений);
- сохранение данных в формате CSV.

Файл после парсинга:  
`data/raw/rbc_news.csv`

---

## 2. Предобработка

Очистка текстов выполняется с помощью `pandas` и простых регулярных выражений:
- удаляются ссылки и знаки препинания;
- текст приводится к нижнему регистру;
- создаётся поле `clean_text` и вычисляется длина поста в словах.

Результат сохраняется в  
`data/processed/rbc_news_clean.csv`

---

## 3. Разведочный анализ (EDA)

Для анализа использованы библиотеки `matplotlib`, `wordcloud` и `nltk`.  
Построены:
- частотный словарь (топ-30 слов),
- частые биграммы,
- облако слов.

Файл с визуализацией:  
`reports/figures/wordcloud.png`

---

## 4. Используемые инструменты
- Python 3.12  
- Telethon, pandas, matplotlib, wordcloud, nltk  

Структура проекта разделена на:
- `src/` — основной код (API, обработка, анализ);
- `scripts/` — отдельные исполняемые скрипты для запуска по шагам;
- `data/` — результаты парсинга;
- `reports/` — визуализации и графики.

---

## 5. Дальнейшие шаги
- добавить несколько каналов для сравнения тем и лексики;
- внедрить лемматизацию (pymorphy2);
- добавить анализ тональности текста;
- собрать небольшой дашборд на Streamlit.

---

## Авторизация
Перед запуском нужно создать `.env` с параметрами подключения:

---

### Для команды
Инструкция по запуску и порядку работы со скриптами описана здесь:  
[fast_start.md](fast_start.md)

---

### Для Надежды
Краткий отчёт о проделанной работе и промежуточные результаты:  
[report.md](report.md)